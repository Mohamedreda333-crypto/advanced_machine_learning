{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "  <h1><b>🌿🔍 Advanced Plant Health Classifier – Model 2: Disease Detection Stage 🧠🌾</b></h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🖼️ Healthy vs Infected Images\n",
        "\n",
        "<div style=\"display: flex; justify-content: center; align-items: center; gap: 20px;\">\n",
        "\n",
        "  <div style=\"text-align: center;\">\n",
        "    <img src=\"https://storage.googleapis.com/kagglesdsdata/datasets/1541807/2542588/PlantVillage/train/Blueberry___healthy/0293e23d-2961-4271-9a6c-1a568d942887___RS_HL%205297.JPG?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250605%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250605T025638Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=8756f83db3cc86e13a22baaca3a863e635bb2013f8edfcc40da94bfbe54664fed2017bce4027446d00be5a79cc0220f980e6da75cb537f619d272f1092838bc8bd585bbaa01dfaaa67f32e5671d89d22396a6cbd20593b5f4b5ddacd392df75d9952c3e871fcf11e506a8d84f2cf14e140a70d5819e347e27d891301914562c49fb380dfbadb50d646cd6fb52978bb3817dbc7420feb212d7056203446c87dd69b4665f71651100a52063d66515948778182491e10722d8092fe0130bd983b907e72ec915a517e578aedb4e27a6dbd7fa7cd1c5641b8893664ce850fbf78d94c5c7f5b0adaff19ac172ca3b0e8ff80194cae220045a6db044e2802ec00b9d58a\" width=\"200\"/>\n",
        "    <p>✅ Healthy Blueberry Image 1</p>\n",
        "  </div>\n",
        "\n",
        "  <div style=\"text-align: center;\">\n",
        "    <img src=\"https://storage.googleapis.com/kagglesdsdata/datasets/1541807/2542588/PlantVillage/train/Apple___healthy/011d02f3-5c3c-4484-a384-b1a0a0dbdec1___RS_HL%207544.JPG?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250605%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250605T025721Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=8ac8b5db466c2bb415724bf9621e05223032cf0d42dda7939fd377c38438414843e5c6723414981573c05d8f61bfc7699d7928b970b74b2f63437f6b401c12cee04d784fe3b0c0e6704885025cb0cf0e09899ec8584d531a9f3cb0bf1d5c39c4e214d657a85527849776973c6152bd5e3128960b338eddc2b22382f61f4f8266ec076ac0fd99b0a1488846b0aaf5b5b39132966a9644fcceba13849d789794f0e284f712111843c2e5684a7749991db6fb1c87a946f947fe8d3f073231faf644c60937b26971c0ef8dff49488f6b42579a30061c003b1cc9cfc04400ae91ad247977d275c1e7fe6672e15ee02b9c9fdd7fbad38522f6eb49e583b0fe66888c06\n",
        "    \" width=\"200\"/>\n",
        "    <p>✅ Healthy Apple Image 2</p>\n",
        "  </div>\n",
        "\n",
        "  <div style=\"text-align: center;\">\n",
        "    <img src=\"https://storage.googleapis.com/kagglesdsdata/datasets/1541807/2542588/PlantVillage/train/Apple___Apple_scab/0208f4eb-45a4-4399-904e-989ac2c6257c___FREC_Scab%203037.JPG?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250605%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250605T025753Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=668f42491b2a47a661cf1c84f16fe937b152686243c96eed266d3d6386bbd08501e4aa97f6d7e66524f7520c96dd34792f6aac6e838df82e265c8ad483c645383014272708b4ffdf0dd6b7f6948d5b40f1335e0264c953b6e2e3457a04d737996d0419dded2580a2f3e2c2cf9190e6dbaf7ce1250951e37f277d703152b306152225d2763fc6669cd8175c56e74111fc68f8875251ee01746dde5b9f1a5b13e8f96d2a7249059f0e9b6129d7f8e1bef8235208a008da5266d95e6dcf7ed9cdfec9397ed5ae522e5a3f3c02321b288e19ae4b6cf2e4a36bd610ca3817c9ae142b4de15892ec96b85d81e7fcf255e0bc3af979a14be6e69f0081f4c45624ee84da\" width=\"200\"/>\n",
        "    <p>❌ Infected Apple Image 1</p>\n",
        "  </div>\n",
        "\n",
        "  <div style=\"text-align: center;\">\n",
        "    <img src=\"https://storage.googleapis.com/kagglesdsdata/datasets/1541807/2542588/PlantVillage/train/Potato___Early_blight/04ee51b6-07e2-4182-84f8-46b22c8938a2___RS_Early.B%208091.JPG?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250604%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250604T010458Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=953322b6fb6c004a86d2095efbc42eff766f26475ad3a6319b2372048e58cf656f12220ae34b961abb03722b69d674d9f5a72be0cceddf443bc80bb3be31aba19344790a4d38419f07c3b165045c94671c4f30aecdf109069da57f62c8281cac1ac4df2f82edf5b0cb3de47a50a5b35a6a7904738ae11f7e726aa442dc5357c2d8207964a735f6bdc6eed0edc0452a893cde11cca49f01e33f2fd8d434ccb437984972a6e78d28b9475fa2f4be3f2f1f8c16d3046ed32d7b1e3f51b2de9933374de93d8b731e7ed3494cc2eb6135779bc34ce6b69c5484fd86d83a5fb794113f329a400bdb4c097cbec3eac6b43a1abd1ca9e1a97dd5d4cea1a4e74e16e7ecab\" width=\"200\"/>\n",
        "    <p>❌ Infected Potato Image 2</p>\n",
        "  </div>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸\n",
        "\n",
        "🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **My Details**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‎‧₊˚✿[My Name]✿˚ : **Mohamed Reda Ramadan Khamis**\n",
        "### ‎‧₊˚✿[Phone Number]✿˚ : **01554725661**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸\n",
        "\n",
        "🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🔗 Mounting Google Drive for Data Access 📁***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z2TK28Beol2",
        "outputId": "7b249974-128b-464e-9ad6-fce26ee5bd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***📥 Downloading PlantDoc Dataset from Kaggle 🌱***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXv9J0K3eplh",
        "outputId": "48956752-89cf-4843-a383-7c5c9cade53f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping, found downloaded files in \"./plantdoc-dataset\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download (\"https://www.kaggle.com/datasets/nirmalsankalana/plantdoc-dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***📥 Downloading PlantVillage Dataset from Kaggle 🌱***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VO8LwoB_9g7",
        "outputId": "2cb1ee4c-8870-4b26-91bf-4f10099efa5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping, found downloaded files in \"./plantdisease\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download (\"https://www.kaggle.com/datasets/emmarex/plantdisease\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🔗 Mounting Google Drive 📂***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDCHjMRKesVY",
        "outputId": "5cebe110-ae65-432f-ecf1-a1c670d1e9f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***📦 Importing Required Libraries & Modules 🧠🛠️***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9HHfU-lCk19u"
      },
      "outputs": [],
      "source": [
        "import os , shutil\n",
        "import sys\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, applications, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import concurrent.futures\n",
        "import json\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from typing import Tuple, Dict, Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "knU4oqD_I27n"
      },
      "outputs": [],
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('plant_disease.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class for the plant disease classification system\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***⚙️ Configuration Class for Paths & Hyperparameters 📁🧪***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpmJnCzx7iYg"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration with your exact paths\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize configuration with dataset paths, model directories,\n",
        "        hyperparameters, and class labels for the Plant Disease Detection project.\n",
        "        Automatically sets up necessary directories for data, models, and logs.\n",
        "        \"\"\"\n",
        "        # Base directory (Colab environment)\n",
        "        self.BASE_DIR = \"/content/drive/MyDrive/Graduation Project\"\n",
        "\n",
        "        # Dataset source paths\n",
        "        self.PLANTVILLAGE_DIR = \"/content/plantdisease/PlantVillage\"\n",
        "        self.PLANTDOC_TRAIN_DIR = \"/content/plantdoc-dataset/train\"\n",
        "        self.PLANTDOC_TEST_DIR = \"/content/plantdoc-dataset/test\"\n",
        "\n",
        "        # Processed data paths\n",
        "        self.DATA_DIR = os.path.join(self.BASE_DIR, \"plant_health_data\")\n",
        "        self.HEALTHY_DIR = os.path.join(self.DATA_DIR, \"Healthy\")\n",
        "        self.INFECTED_DIR = os.path.join(self.DATA_DIR, \"Infected\")\n",
        "\n",
        "        # Model paths\n",
        "        self.MODEL_NAME = \"model2_healthy_vs_infected\"\n",
        "        self.MODEL_DIR = os.path.join(self.BASE_DIR, f\"saved_models/{self.MODEL_NAME}\")\n",
        "        self.LOG_DIR = os.path.join(self.BASE_DIR, f\"training_logs/{self.MODEL_NAME}\")\n",
        "\n",
        "        # Model hyperparameters\n",
        "        self.IMG_SIZE = (384, 384)\n",
        "        self.BATCH_SIZE = 32\n",
        "        self.EPOCHS = 50\n",
        "        self.SEED = 42\n",
        "\n",
        "        # Anti-overfitting\n",
        "        self.DROPOUT_RATE = 0.5\n",
        "        self.L2_REG = 0.001\n",
        "\n",
        "        # Class names\n",
        "        self.CLASS_NAMES = ['healthy', 'infected']\n",
        "\n",
        "        # Create directories\n",
        "        self.setup_dirs()\n",
        "\n",
        "    def setup_dirs(self):\n",
        "        \"\"\"\n",
        "        Ensure that all required directories exist by creating them if missing.\n",
        "        This includes data folders, model checkpoints, and training log directories.\n",
        "        Logs a confirmation message upon successful creation.\n",
        "        \"\"\"\n",
        "        #Create all necessary directories\n",
        "        os.makedirs(self.DATA_DIR, exist_ok=True)\n",
        "        os.makedirs(self.HEALTHY_DIR, exist_ok=True)\n",
        "        os.makedirs(self.INFECTED_DIR, exist_ok=True)\n",
        "        os.makedirs(self.MODEL_DIR, exist_ok=True)\n",
        "        os.makedirs(self.LOG_DIR, exist_ok=True)\n",
        "        logger.info(\"All directories created successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvZqkbQ7Wdlr"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "def safe_read_image(img_path):\n",
        "    \"\"\"\n",
        "    Safely load an image from the specified path and convert it to RGB format.\n",
        "    Returns the image object if successful, otherwise logs the error and returns None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to load image {img_path}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🧹 Data Preparation & Augmentation Pipeline 🌿🧬***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq9vNvAnHnja"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "    \"\"\"Handles dataset preparation and augmentation\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"\n",
        "        Initialize with configuration and define healthy/infected source folders\n",
        "        based on dataset exploration.\n",
        "\n",
        "        Args:\n",
        "            config (Config): Configuration object containing dataset and model paths.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        # Manually after Explore PlantVillage Dataset and PLnatDoc Dataset\n",
        "        self.healthy_sources = {\n",
        "            'plantvillage': [\n",
        "                'Pepper__bell___healthy',\n",
        "                'Potato___healthy',\n",
        "                'Tomato_healthy'\n",
        "            ],\n",
        "            'plantdoc_train': [\n",
        "                'Apple_leaf',\n",
        "                'Bell_pepper_leaf',\n",
        "                'Cherry_leaf',\n",
        "                'grape_leaf',\n",
        "                'Peach_leaf',\n",
        "                'Raspberry_leaf',\n",
        "                'Soyabean_leaf',\n",
        "                'Strawberry_leaf',\n",
        "                'Tomato_leaf'\n",
        "            ],\n",
        "            'plantdoc_test': [\n",
        "                'Apple_leaf',\n",
        "                'Bell_pepper_leaf',\n",
        "                'Cherry_leaf',\n",
        "                'grape_leaf',\n",
        "                'Peach_leaf',\n",
        "                'Raspberry_leaf',\n",
        "                'Soyabean_leaf',\n",
        "                'Strawberry_leaf',\n",
        "                'Tomato_leaf'\n",
        "            ]\n",
        "        }\n",
        "        self.infected_sources = {\n",
        "            'plantvillage': [\n",
        "                'Pepper__bell___Bacterial_spot',\n",
        "                'Potato___Early_blight',\n",
        "                'Potato___Late_blight',\n",
        "                'Tomato__Tomato_mosaic_virus',\n",
        "                'Tomato_Bacterial_spot',\n",
        "                'Tomato_Early_blight',\n",
        "                'Tomato_Late_blight',\n",
        "                'Tomato_Leaf_Mold',\n",
        "                'Tomato_Septoria_leaf_spot'\n",
        "            ],\n",
        "            'plantdoc_train': [\n",
        "                'Apple_rust_leaf',\n",
        "                'Apple_Scab_Leaf',\n",
        "                'Bell_pepper_leaf_spot',\n",
        "                'Corn_Gray_leaf_spot',\n",
        "                'Corn_leaf_blight',\n",
        "                'Corn_rust_leaf',\n",
        "                'grape_leaf_black_rot',\n",
        "                'Potato_leaf_early_blight',\n",
        "                'Potato_leaf_late_blight',\n",
        "                'Tomato_leaf_bacterial_spot',\n",
        "                'Tomato_leaf_late_blight',\n",
        "                'Tomato_leaf_mosaic_virus'\n",
        "            ],\n",
        "            'plantdoc_test': [\n",
        "                'Apple_rust_leaf',\n",
        "                'Apple_Scab_Leaf',\n",
        "                'Bell_pepper_leaf_spot',\n",
        "                'Corn_Gray_leaf_spot',\n",
        "                'Corn_leaf_blight',\n",
        "                'Corn_rust_leaf',\n",
        "                'grape_leaf_black_rot',\n",
        "                'Potato_leaf_early_blight',\n",
        "                'Potato_leaf_late_blight',\n",
        "                'Tomato_leaf_bacterial_spot',\n",
        "                'Tomato_leaf_late_blight',\n",
        "                'Tomato_leaf_mosaic_virus'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def clear_directory(self, dir_path: str):\n",
        "        \"\"\"\n",
        "        Safely delete all files in the specified directory if it exists.\n",
        "\n",
        "        Args:\n",
        "            dir_path (str): Path to the directory to clear.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        \"\"\"Empty a directory if it exists\"\"\"\n",
        "        if os.path.exists(dir_path):\n",
        "            for filename in os.listdir(dir_path):\n",
        "                file_path = os.path.join(dir_path, filename)\n",
        "                try:\n",
        "                    if os.path.isfile(file_path):\n",
        "                        os.unlink(file_path)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Failed to delete {file_path}: {e}\")\n",
        "\n",
        "    def verify_image(self, img_path: str) -> bool:\n",
        "        \"\"\"\n",
        "        Verify the integrity of an image file, ensuring it is not corrupted.\n",
        "\n",
        "        Args:\n",
        "            img_path (str): Path to the image file.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the image is valid, False otherwise.\n",
        "        \"\"\"\n",
        "        #Verify if an image is valid\"\"\"\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img.verify()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Invalid image {img_path}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def process_dataset(self):\n",
        "        \"\"\"\n",
        "        Prepare the dataset by clearing target directories, verifying images,\n",
        "        copying healthy and infected images from sources, and balancing classes.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        #Prepare and balance the dataset\"\"\"\n",
        "        logger.info(\"Starting dataset preparation\")\n",
        "\n",
        "        # Clear existing data\n",
        "        self.clear_directory(self.config.HEALTHY_DIR)\n",
        "        self.clear_directory(self.config.INFECTED_DIR)\n",
        "\n",
        "        # Process healthy images\n",
        "        healthy_count = 0\n",
        "        for source_name, folders in self.healthy_sources.items():\n",
        "            base_dir = getattr(self.config, f\"{source_name.upper()}_DIR\")\n",
        "\n",
        "            for folder in tqdm(folders, desc=f\"Processing {source_name} healthy\"):\n",
        "                src_folder = os.path.join(base_dir, folder)\n",
        "                if not os.path.exists(src_folder):\n",
        "                    logger.warning(f\"Source folder not found: {src_folder}\")\n",
        "                    continue\n",
        "\n",
        "                for file in os.listdir(src_folder):\n",
        "                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        src_path = os.path.join(src_folder, file)\n",
        "                        if self.verify_image(src_path):\n",
        "                            dest_path = os.path.join(\n",
        "                                self.config.HEALTHY_DIR,\n",
        "                                f\"{source_name}_{folder}_{file}\".replace(\" \", \"_\")\n",
        "                            )\n",
        "                            shutil.copy2(src_path, dest_path)\n",
        "                            healthy_count += 1\n",
        "\n",
        "        # Process infected images\n",
        "        infected_count = 0\n",
        "        for source_name, folders in self.infected_sources.items():\n",
        "            base_dir = getattr(self.config, f\"{source_name.upper()}_DIR\")\n",
        "\n",
        "            for folder in tqdm(folders, desc=f\"Processing {source_name} infected\"):\n",
        "                src_folder = os.path.join(base_dir, folder)\n",
        "                if not os.path.exists(src_folder):\n",
        "                    logger.warning(f\"Source folder not found: {src_folder}\")\n",
        "                    continue\n",
        "\n",
        "                for file in os.listdir(src_folder):\n",
        "                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        src_path = os.path.join(src_folder, file)\n",
        "                        if self.verify_image(src_path):\n",
        "                            dest_path = os.path.join(\n",
        "                                self.config.INFECTED_DIR,\n",
        "                                f\"{source_name}_{folder}_{file}\".replace(\" \", \"_\")\n",
        "                            )\n",
        "                            shutil.copy2(src_path, dest_path)\n",
        "                            infected_count += 1\n",
        "\n",
        "        # Balance classes\n",
        "        self.balance_classes(healthy_count, infected_count)\n",
        "\n",
        "        logger.info(f\"Dataset preparation complete. Healthy: {len(os.listdir(self.config.HEALTHY_DIR))}, \"\n",
        "                   f\"Infected: {len(os.listdir(self.config.INFECTED_DIR))}\")\n",
        "\n",
        "    def balance_classes(self, healthy_count: int, infected_count: int):\n",
        "        \"\"\"\n",
        "        Balance the number of images in healthy and infected classes by reducing\n",
        "        or augmenting images to make class counts equal.\n",
        "\n",
        "        Args:\n",
        "            healthy_count (int): Number of healthy images.\n",
        "            infected_count (int): Number of infected images.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        #Balance classes to have equal counts\"\"\"\n",
        "        if healthy_count == infected_count:\n",
        "            return\n",
        "\n",
        "        if healthy_count > infected_count:\n",
        "            self.reduce_class(self.config.HEALTHY_DIR, healthy_count - infected_count)\n",
        "        else:\n",
        "            self.augment_class(self.config.HEALTHY_DIR, infected_count - healthy_count)\n",
        "\n",
        "    def reduce_class(self, class_dir: str, reduce_by: int):\n",
        "        \"\"\"\n",
        "        Randomly remove a specified number of images from a class directory to balance data.\n",
        "\n",
        "        Args:\n",
        "            class_dir (str): Path to the class directory.\n",
        "            reduce_by (int): Number of images to remove.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        \"\"\"Reduce number of images in a class\"\"\"\n",
        "        files = os.listdir(class_dir)\n",
        "        files_to_remove = np.random.choice(files, reduce_by, replace=False)\n",
        "\n",
        "        for file in tqdm(files_to_remove, desc=\"Reducing class\"):\n",
        "            os.remove(os.path.join(class_dir, file))\n",
        "\n",
        "    def augment_class(self, class_dir: str, augment_by: int):\n",
        "      \"\"\"\n",
        "        Perform image augmentation to increase the number of images in a class\n",
        "        using geometric and photometric transformations.\n",
        "\n",
        "        Args:\n",
        "            class_dir (str): Path to the class directory.\n",
        "            augment_by (int): Number of images to generate via augmentation.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "      \"\"\"Robust image augmentation with proper shape and type handling\"\"\"\n",
        "      datagen = ImageDataGenerator(\n",
        "          rotation_range=20,\n",
        "          width_shift_range=0.1,\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.1,\n",
        "          zoom_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          fill_mode='reflect',\n",
        "          brightness_range=[0.9, 1.1]\n",
        "      )\n",
        "\n",
        "      files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "      for i in tqdm(range(augment_by), desc=\"Augmenting class\"):\n",
        "          img_file = files[i % len(files)]\n",
        "          img_path = os.path.join(class_dir, img_file)\n",
        "\n",
        "          try:\n",
        "              img = Image.open(img_path)\n",
        "              img_array = np.array(img)\n",
        "\n",
        "              # Skip if image is not a proper RGB image\n",
        "              if img_array.ndim != 3 or img_array.shape[2] != 3:\n",
        "                  logger.error(f\"{img_path} is not a 3-channel RGB image\")\n",
        "                  continue\n",
        "\n",
        "              # Ensure uint8 dtype\n",
        "              if img_array.dtype != np.uint8:\n",
        "                  img_array = img_array.astype(np.uint8)\n",
        "\n",
        "              # Expand dims for batch\n",
        "              img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "              # Apply augmentation\n",
        "              augmented = datagen.random_transform(img_array[0])\n",
        "\n",
        "              # Save augmented image\n",
        "              save_path = os.path.join(class_dir, f\"aug_{i}_{img_file}\")\n",
        "              Image.fromarray(augmented.astype(np.uint8)).save(save_path, quality=95)\n",
        "\n",
        "          except Exception as e:\n",
        "              logger.error(f\"Failed to augment {img_path}: {str(e)}\")\n",
        "              continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🚜 Plant Disease Trainer: Model Building, Training & Fine-Tuning***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-M5Os6OJzFk"
      },
      "outputs": [],
      "source": [
        "class PlantDiseaseTrainer:\n",
        "    \"\"\"Handles model building, training, fine-tuning, and saving.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"\n",
        "        Initialize trainer with configuration.\n",
        "\n",
        "        Args:\n",
        "            config (Config): Configuration object containing paths, hyperparameters, etc.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Build a binary classification model using EfficientNetB4 as backbone.\n",
        "\n",
        "        Returns:\n",
        "            tf.keras.Model: Compiled Keras model ready for training.\n",
        "        \"\"\"\n",
        "        \"\"\"Build a binary classification model using EfficientNetB4 as backbone.\"\"\"\n",
        "        base_model = applications.EfficientNetB4(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(*self.config.IMG_SIZE, 3)\n",
        "            #drop_connect_rate=0.4\n",
        "        )\n",
        "        base_model.trainable = False\n",
        "\n",
        "        inputs = tf.keras.Input(shape=(*self.config.IMG_SIZE, 3))\n",
        "        x = applications.efficientnet.preprocess_input(inputs)\n",
        "        x = base_model(x)\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dropout(self.config.DROPOUT_RATE)(x)\n",
        "        x = layers.Dense(512, activation='swish',\n",
        "                         kernel_regularizer=regularizers.l2(self.config.L2_REG))(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(self.config.DROPOUT_RATE / 2)(x)\n",
        "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        self.model = models.Model(inputs, outputs)\n",
        "        self.model.compile(\n",
        "            optimizer=optimizers.Adam(1e-4),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.Precision(name='precision'),\n",
        "                     tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        logger.info(\"✅ Model built successfully\")\n",
        "        return self.model\n",
        "\n",
        "    def get_callbacks(self):\n",
        "        \"\"\"\n",
        "        Create a list of Keras callbacks for training.\n",
        "\n",
        "        Returns:\n",
        "            list: List of Keras callback instances (EarlyStopping, ModelCheckpoint, etc.).\n",
        "        \"\"\"\n",
        "        \"\"\"Returns list of Keras callbacks with dynamic timestamp paths.\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        return [\n",
        "            callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=10,\n",
        "                                    restore_best_weights=True, verbose=1),\n",
        "            callbacks.ModelCheckpoint(\n",
        "                filepath=os.path.join(self.config.MODEL_DIR, f'best_model_{timestamp}.keras'),\n",
        "                monitor='val_auc', save_best_only=True, verbose=1),\n",
        "            callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "            callbacks.TensorBoard(log_dir=os.path.join(self.config.LOG_DIR, timestamp)),\n",
        "            callbacks.CSVLogger(os.path.join(self.config.LOG_DIR, f'training_{timestamp}.csv'))\n",
        "        ]\n",
        "\n",
        "    def create_data_pipeline(self, subset: str) -> tf.data.Dataset:\n",
        "        \"\"\"\n",
        "        Create a TensorFlow data pipeline for training or validation.\n",
        "\n",
        "        Args:\n",
        "            subset (str): Either 'training' or 'validation' to specify dataset split.\n",
        "\n",
        "        Returns:\n",
        "            tf.data.Dataset: Prefetched and optionally augmented dataset.\n",
        "        \"\"\"\n",
        "        \"\"\"Create a dataset pipeline for training or validation.\"\"\"\n",
        "        ds = tf.keras.utils.image_dataset_from_directory(\n",
        "            self.config.DATA_DIR,\n",
        "            validation_split=0.2,\n",
        "            subset=subset,\n",
        "            seed=self.config.SEED,\n",
        "            image_size=self.config.IMG_SIZE,\n",
        "            batch_size=self.config.BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        if subset == 'training':\n",
        "            aug = tf.keras.Sequential([\n",
        "                layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "                layers.RandomRotation(0.25),\n",
        "                layers.RandomZoom(0.2),\n",
        "                layers.RandomContrast(0.1)\n",
        "            ])\n",
        "            ds = ds.map(lambda x, y: (aug(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "        return ds.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train the model including initial frozen base training and fine-tuning.\n",
        "\n",
        "        Returns:\n",
        "            tf.keras.callbacks.History or None: Training history object if success,\n",
        "            otherwise None if training failed.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.model is None:\n",
        "                self.build_model()\n",
        "\n",
        "            # Load datasets\n",
        "            train_ds = self.create_data_pipeline('training')\n",
        "            val_ds = self.create_data_pipeline('validation')\n",
        "\n",
        "            # Train the model (frozen base)\n",
        "            logger.info(\"🚀 Starting model training\")\n",
        "            self.history = self.model.fit(\n",
        "                train_ds,\n",
        "                validation_data=val_ds,\n",
        "                epochs=self.config.EPOCHS,\n",
        "                callbacks=self.get_callbacks(),\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            # Fine-tune model (unfreeze base model)\n",
        "            logger.info(\"🔧 Starting fine-tuning\")\n",
        "            self.model.get_layer('efficientnetb4').trainable = True\n",
        "            self.model.compile(\n",
        "                optimizer=optimizers.Adam(1e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=[\n",
        "                    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                    tf.keras.metrics.Precision(name='precision'),\n",
        "                    tf.keras.metrics.Recall(name='recall'),\n",
        "                    tf.keras.metrics.AUC(name='auc')\n",
        "                ]\n",
        "            )\n",
        "            self.model.fit(\n",
        "                train_ds,\n",
        "                validation_data=val_ds,\n",
        "                epochs=10,\n",
        "                callbacks=self.get_callbacks(),\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            logger.info(\"✅ Training and fine-tuning completed successfully\")\n",
        "            return self.history\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Training failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Save the trained model in both .keras and .h5 formats.\n",
        "\n",
        "        Returns:\n",
        "            str: Filepath of the saved .keras model.\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        keras_path = os.path.join(self.config.MODEL_DIR, f'final_model_{timestamp}.keras')\n",
        "        h5_path = os.path.join(self.config.MODEL_DIR, f'final_model_{timestamp}.h5')\n",
        "\n",
        "        self.model.save(keras_path)\n",
        "        self.model.save(h5_path)\n",
        "\n",
        "        logger.info(f\"✅ Model saved to:\\n  - {keras_path}\\n  - {h5_path}\")\n",
        "        return keras_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🚀 Main Training Pipeline Execution***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mbfpet_KRxD"
      },
      "outputs": [],
      "source": [
        "def main_1():\n",
        "    \"\"\"\n",
        "    Run the full training pipeline using PlantDiseaseTrainer.\n",
        "\n",
        "    Steps:\n",
        "        1. Initialize configuration.\n",
        "        2. Prepare dataset using DataProcessor.\n",
        "        3. Build and train the model.\n",
        "        4. Save the trained model.\n",
        "\n",
        "    Returns:\n",
        "        str: The filepath to the saved Keras model (.keras format).\n",
        "\n",
        "    Raises:\n",
        "        Exception: Propagates any exception that occurs during the training process.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        config = Config()\n",
        "        # Step 1: Prepare dataset\n",
        "        logger.info(\"Starting data preparation\")\n",
        "        processor = DataProcessor(config)\n",
        "        processor.process_dataset()\n",
        "\n",
        "        # Step 2: Train model\n",
        "        logger.info(\"Starting model training\")\n",
        "        trainer = PlantDiseaseTrainer(config)\n",
        "        trainer.build_model()\n",
        "        trainer.train()\n",
        "        keras_model_path = trainer.save_model()\n",
        "\n",
        "        print(\"✅ Training completed successfully\")\n",
        "        return keras_model_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Training failed: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I42sBD5gB0Q5",
        "outputId": "1a27a109-3508-4771-8c8f-86d3bf765347"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing plantvillage healthy: 100%|██████████| 3/3 [00:22<00:00,  7.62s/it]\n",
            "Processing plantdoc_train healthy: 100%|██████████| 9/9 [00:05<00:00,  1.67it/s]\n",
            "Processing plantdoc_test healthy: 100%|██████████| 9/9 [00:00<00:00, 15.43it/s]\n",
            "Processing plantvillage infected: 100%|██████████| 9/9 [01:17<00:00,  8.64s/it]\n",
            "Processing plantdoc_train infected: 100%|██████████| 12/12 [00:10<00:00,  1.13it/s]\n",
            "Processing plantdoc_test infected: 100%|██████████| 12/12 [00:01<00:00, 10.00it/s]\n",
            "Augmenting class:   7%|▋         | 576/8595 [00:35<02:59, 44.78it/s]ERROR:__main__:/content/drive/MyDrive/Graduation Project/plant_health_data/Healthy/plantvillage_Pepper__bell___healthy_42f083e2-272d-4f83-ad9a-573ee90e50ec___Screen_Shot_2015-05-06_at_4.01.13_PM.png is not a 3-channel RGB image\n",
            "Augmenting class:  40%|███▉      | 3437/8595 [03:10<38:45,  2.22it/s]ERROR:__main__:/content/drive/MyDrive/Graduation Project/plant_health_data/Healthy/plantdoc_train_grape_leaf_train_grape_leaf_10.jpg is not a 3-channel RGB image\n",
            "Augmenting class:  52%|█████▏    | 4505/8595 [07:22<01:40, 40.69it/s]ERROR:__main__:/content/drive/MyDrive/Graduation Project/plant_health_data/Healthy/plantvillage_Pepper__bell___healthy_42f083e2-272d-4f83-ad9a-573ee90e50ec___Screen_Shot_2015-05-06_at_4.01.13_PM.png is not a 3-channel RGB image\n",
            "Augmenting class:  86%|████████▌ | 7364/8595 [09:59<09:24,  2.18it/s]ERROR:__main__:/content/drive/MyDrive/Graduation Project/plant_health_data/Healthy/plantdoc_train_grape_leaf_train_grape_leaf_10.jpg is not a 3-channel RGB image\n",
            "Augmenting class:  98%|█████████▊| 8429/8595 [14:13<00:04, 40.66it/s]ERROR:__main__:/content/drive/MyDrive/Graduation Project/plant_health_data/Healthy/plantvillage_Pepper__bell___healthy_42f083e2-272d-4f83-ad9a-573ee90e50ec___Screen_Shot_2015-05-06_at_4.01.13_PM.png is not a 3-channel RGB image\n",
            "Augmenting class: 100%|██████████| 8595/8595 [14:17<00:00, 10.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
            "\u001b[1m71686520/71686520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Found 25039 files belonging to 2 classes.\n",
            "Using 20032 files for training.\n",
            "Found 25039 files belonging to 2 classes.\n",
            "Using 5007 files for validation.\n",
            "Epoch 1/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.8359 - auc: 0.9107 - loss: 1.1325 - precision: 0.8517 - recall: 0.8118\n",
            "Epoch 1: val_auc improved from inf to 0.99551, saving model to /content/drive/MyDrive/Graduation Project/saved_models/model2_healthy_vs_infected/best_model_20250509-134647.keras\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 367ms/step - accuracy: 0.8360 - auc: 0.9107 - loss: 1.1323 - precision: 0.8517 - recall: 0.8119 - val_accuracy: 0.9718 - val_auc: 0.9955 - val_loss: 0.7678 - val_precision: 0.9819 - val_recall: 0.9622 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9183 - auc: 0.9740 - loss: 0.8527 - precision: 0.9270 - recall: 0.9068\n",
            "Epoch 2: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9182 - auc: 0.9740 - loss: 0.8526 - precision: 0.9270 - recall: 0.9068 - val_accuracy: 0.9730 - val_auc: 0.9964 - val_loss: 0.6565 - val_precision: 0.9870 - val_recall: 0.9595 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9228 - auc: 0.9785 - loss: 0.7453 - precision: 0.9278 - recall: 0.9159\n",
            "Epoch 3: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 195ms/step - accuracy: 0.9228 - auc: 0.9785 - loss: 0.7453 - precision: 0.9278 - recall: 0.9159 - val_accuracy: 0.9782 - val_auc: 0.9966 - val_loss: 0.5777 - val_precision: 0.9845 - val_recall: 0.9725 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9275 - auc: 0.9785 - loss: 0.6704 - precision: 0.9313 - recall: 0.9219\n",
            "Epoch 4: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.9275 - auc: 0.9785 - loss: 0.6704 - precision: 0.9313 - recall: 0.9219 - val_accuracy: 0.9593 - val_auc: 0.9967 - val_loss: 0.5397 - val_precision: 0.9920 - val_recall: 0.9272 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9331 - auc: 0.9820 - loss: 0.5958 - precision: 0.9387 - recall: 0.9259\n",
            "Epoch 5: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9331 - auc: 0.9820 - loss: 0.5958 - precision: 0.9387 - recall: 0.9259 - val_accuracy: 0.9840 - val_auc: 0.9974 - val_loss: 0.4507 - val_precision: 0.9877 - val_recall: 0.9807 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9414 - auc: 0.9840 - loss: 0.5306 - precision: 0.9458 - recall: 0.9355\n",
            "Epoch 6: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 193ms/step - accuracy: 0.9414 - auc: 0.9840 - loss: 0.5306 - precision: 0.9458 - recall: 0.9355 - val_accuracy: 0.9644 - val_auc: 0.9973 - val_loss: 0.4303 - val_precision: 0.9929 - val_recall: 0.9366 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9380 - auc: 0.9833 - loss: 0.4911 - precision: 0.9417 - recall: 0.9330\n",
            "Epoch 7: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9380 - auc: 0.9833 - loss: 0.4911 - precision: 0.9417 - recall: 0.9330 - val_accuracy: 0.9808 - val_auc: 0.9975 - val_loss: 0.3629 - val_precision: 0.9842 - val_recall: 0.9780 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9428 - auc: 0.9868 - loss: 0.4351 - precision: 0.9466 - recall: 0.9376\n",
            "Epoch 8: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.9428 - auc: 0.9868 - loss: 0.4351 - precision: 0.9466 - recall: 0.9376 - val_accuracy: 0.9752 - val_auc: 0.9971 - val_loss: 0.3375 - val_precision: 0.9903 - val_recall: 0.9606 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9472 - auc: 0.9875 - loss: 0.3966 - precision: 0.9526 - recall: 0.9406\n",
            "Epoch 9: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.9472 - auc: 0.9875 - loss: 0.3966 - precision: 0.9526 - recall: 0.9406 - val_accuracy: 0.9816 - val_auc: 0.9980 - val_loss: 0.2924 - val_precision: 0.9842 - val_recall: 0.9795 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9457 - auc: 0.9879 - loss: 0.3664 - precision: 0.9491 - recall: 0.9416\n",
            "Epoch 10: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 193ms/step - accuracy: 0.9457 - auc: 0.9879 - loss: 0.3664 - precision: 0.9491 - recall: 0.9416 - val_accuracy: 0.9808 - val_auc: 0.9969 - val_loss: 0.2737 - val_precision: 0.9869 - val_recall: 0.9752 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9505 - auc: 0.9890 - loss: 0.3329 - precision: 0.9515 - recall: 0.9488\n",
            "Epoch 11: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9505 - auc: 0.9890 - loss: 0.3329 - precision: 0.9515 - recall: 0.9488 - val_accuracy: 0.9802 - val_auc: 0.9975 - val_loss: 0.2478 - val_precision: 0.9908 - val_recall: 0.9701 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9502 - auc: 0.9893 - loss: 0.3088 - precision: 0.9512 - recall: 0.9485\n",
            "Epoch 12: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9502 - auc: 0.9893 - loss: 0.3088 - precision: 0.9512 - recall: 0.9485 - val_accuracy: 0.9846 - val_auc: 0.9973 - val_loss: 0.2271 - val_precision: 0.9839 - val_recall: 0.9858 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9564 - auc: 0.9915 - loss: 0.2768 - precision: 0.9576 - recall: 0.9544\n",
            "Epoch 13: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9564 - auc: 0.9915 - loss: 0.2768 - precision: 0.9576 - recall: 0.9544 - val_accuracy: 0.9814 - val_auc: 0.9976 - val_loss: 0.2100 - val_precision: 0.9869 - val_recall: 0.9764 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9525 - auc: 0.9900 - loss: 0.2698 - precision: 0.9536 - recall: 0.9508\n",
            "Epoch 14: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 196ms/step - accuracy: 0.9525 - auc: 0.9900 - loss: 0.2698 - precision: 0.9537 - recall: 0.9508 - val_accuracy: 0.9840 - val_auc: 0.9976 - val_loss: 0.1895 - val_precision: 0.9877 - val_recall: 0.9807 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9568 - auc: 0.9904 - loss: 0.2501 - precision: 0.9601 - recall: 0.9525\n",
            "Epoch 15: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 194ms/step - accuracy: 0.9568 - auc: 0.9904 - loss: 0.2501 - precision: 0.9601 - recall: 0.9525 - val_accuracy: 0.9834 - val_auc: 0.9974 - val_loss: 0.1790 - val_precision: 0.9862 - val_recall: 0.9811 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9547 - auc: 0.9909 - loss: 0.2359 - precision: 0.9564 - recall: 0.9526\n",
            "Epoch 16: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 191ms/step - accuracy: 0.9547 - auc: 0.9909 - loss: 0.2359 - precision: 0.9564 - recall: 0.9526 - val_accuracy: 0.9842 - val_auc: 0.9978 - val_loss: 0.1644 - val_precision: 0.9854 - val_recall: 0.9835 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9601 - auc: 0.9925 - loss: 0.2164 - precision: 0.9642 - recall: 0.9552\n",
            "Epoch 17: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 195ms/step - accuracy: 0.9601 - auc: 0.9925 - loss: 0.2164 - precision: 0.9642 - recall: 0.9552 - val_accuracy: 0.9838 - val_auc: 0.9973 - val_loss: 0.1568 - val_precision: 0.9889 - val_recall: 0.9791 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9545 - auc: 0.9923 - loss: 0.2101 - precision: 0.9584 - recall: 0.9496\n",
            "Epoch 18: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 192ms/step - accuracy: 0.9545 - auc: 0.9923 - loss: 0.2101 - precision: 0.9584 - recall: 0.9496 - val_accuracy: 0.9838 - val_auc: 0.9975 - val_loss: 0.1475 - val_precision: 0.9835 - val_recall: 0.9847 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9631 - auc: 0.9936 - loss: 0.1895 - precision: 0.9671 - recall: 0.9584\n",
            "Epoch 19: val_auc did not improve from 0.99551\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 192ms/step - accuracy: 0.9631 - auc: 0.9936 - loss: 0.1895 - precision: 0.9671 - recall: 0.9584 - val_accuracy: 0.9828 - val_auc: 0.9979 - val_loss: 0.1394 - val_precision: 0.9881 - val_recall: 0.9780 - learning_rate: 1.0000e-04\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "Epoch 1/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8744 - auc: 0.9391 - loss: 0.6047 - precision: 0.8767 - recall: 0.8704\n",
            "Epoch 1: val_auc improved from inf to 0.99793, saving model to /content/drive/MyDrive/Graduation Project/saved_models/model2_healthy_vs_infected/best_model_20250509-142828.keras\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 228ms/step - accuracy: 0.8745 - auc: 0.9392 - loss: 0.6045 - precision: 0.8767 - recall: 0.8705 - val_accuracy: 0.9824 - val_auc: 0.9979 - val_loss: 0.2820 - val_precision: 0.9908 - val_recall: 0.9744 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9634 - auc: 0.9925 - loss: 0.3365 - precision: 0.9692 - recall: 0.9566\n",
            "Epoch 2: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 200ms/step - accuracy: 0.9634 - auc: 0.9925 - loss: 0.3365 - precision: 0.9692 - recall: 0.9566 - val_accuracy: 0.9878 - val_auc: 0.9982 - val_loss: 0.2663 - val_precision: 0.9948 - val_recall: 0.9811 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9757 - auc: 0.9957 - loss: 0.3016 - precision: 0.9768 - recall: 0.9744\n",
            "Epoch 3: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 204ms/step - accuracy: 0.9757 - auc: 0.9957 - loss: 0.3016 - precision: 0.9768 - recall: 0.9744 - val_accuracy: 0.9916 - val_auc: 0.9986 - val_loss: 0.2559 - val_precision: 0.9972 - val_recall: 0.9862 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9812 - auc: 0.9974 - loss: 0.2821 - precision: 0.9820 - recall: 0.9801\n",
            "Epoch 4: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 201ms/step - accuracy: 0.9812 - auc: 0.9974 - loss: 0.2821 - precision: 0.9820 - recall: 0.9801 - val_accuracy: 0.9938 - val_auc: 0.9990 - val_loss: 0.2442 - val_precision: 0.9968 - val_recall: 0.9909 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9852 - auc: 0.9981 - loss: 0.2670 - precision: 0.9847 - recall: 0.9855\n",
            "Epoch 5: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 201ms/step - accuracy: 0.9852 - auc: 0.9981 - loss: 0.2670 - precision: 0.9847 - recall: 0.9855 - val_accuracy: 0.9946 - val_auc: 0.9990 - val_loss: 0.2396 - val_precision: 0.9984 - val_recall: 0.9909 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9863 - auc: 0.9985 - loss: 0.2573 - precision: 0.9863 - recall: 0.9861\n",
            "Epoch 6: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 201ms/step - accuracy: 0.9863 - auc: 0.9985 - loss: 0.2573 - precision: 0.9863 - recall: 0.9861 - val_accuracy: 0.9950 - val_auc: 0.9993 - val_loss: 0.2308 - val_precision: 0.9972 - val_recall: 0.9929 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9864 - auc: 0.9986 - loss: 0.2489 - precision: 0.9866 - recall: 0.9860\n",
            "Epoch 7: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 203ms/step - accuracy: 0.9864 - auc: 0.9986 - loss: 0.2489 - precision: 0.9866 - recall: 0.9860 - val_accuracy: 0.9950 - val_auc: 0.9993 - val_loss: 0.2250 - val_precision: 0.9976 - val_recall: 0.9925 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9909 - auc: 0.9991 - loss: 0.2324 - precision: 0.9902 - recall: 0.9916\n",
            "Epoch 8: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 200ms/step - accuracy: 0.9909 - auc: 0.9991 - loss: 0.2324 - precision: 0.9902 - recall: 0.9916 - val_accuracy: 0.9958 - val_auc: 0.9995 - val_loss: 0.2190 - val_precision: 0.9988 - val_recall: 0.9929 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9903 - auc: 0.9992 - loss: 0.2307 - precision: 0.9899 - recall: 0.9906\n",
            "Epoch 9: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 203ms/step - accuracy: 0.9903 - auc: 0.9992 - loss: 0.2307 - precision: 0.9899 - recall: 0.9906 - val_accuracy: 0.9958 - val_auc: 0.9995 - val_loss: 0.2103 - val_precision: 0.9980 - val_recall: 0.9937 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9934 - auc: 0.9997 - loss: 0.2120 - precision: 0.9936 - recall: 0.9931\n",
            "Epoch 10: val_auc did not improve from 0.99793\n",
            "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 202ms/step - accuracy: 0.9934 - auc: 0.9997 - loss: 0.2120 - precision: 0.9936 - recall: 0.9931 - val_accuracy: 0.9958 - val_auc: 0.9993 - val_loss: 0.2032 - val_precision: 0.9984 - val_recall: 0.9933 - learning_rate: 1.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 9.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Training completed successfully\n"
          ]
        }
      ],
      "source": [
        "# 1. Train and get .keras model path\n",
        "model_path = main_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸\n",
        "\n",
        "🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "  <h1><b>🏁 Training Session Completed Successfully</b></h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🧪 Plant Disease Tester: Model Evaluation & Reporting***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7o7Fx2ECS1S"
      },
      "outputs": [],
      "source": [
        "class PlantDiseaseTester:\n",
        "    \"\"\"Handles model evaluation and reporting.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config, model_path: str = None):\n",
        "        \"\"\"\n",
        "        Initialize tester with config and optionally load a model.\n",
        "\n",
        "        Args:\n",
        "            config (Config): Configuration object containing settings.\n",
        "            model_path (str, optional): Path to a saved model to load. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.model = tf.keras.models.load_model(model_path) if model_path else None\n",
        "        self.test_results = None\n",
        "\n",
        "    def load_model(self, model_path: str):\n",
        "        \"\"\"\n",
        "        Load a trained model from the given path.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): File path of the trained model.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "        logger.info(f\"✅ Model loaded from {model_path}\")\n",
        "\n",
        "    def create_test_dataset(self) -> tf.data.Dataset:\n",
        "        \"\"\"\n",
        "        Create a TensorFlow dataset pipeline for the test/validation data.\n",
        "\n",
        "        Returns:\n",
        "            tf.data.Dataset: Dataset object for test data.\n",
        "        \"\"\"\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            self.config.DATA_DIR,\n",
        "            validation_split=0.1,\n",
        "            subset='validation',\n",
        "            seed=self.config.SEED,\n",
        "            image_size=self.config.IMG_SIZE,\n",
        "            batch_size=self.config.BATCH_SIZE\n",
        "        )\n",
        "\n",
        "    def predict_with_tta(self, images, n=5):\n",
        "        \"\"\"\n",
        "        Perform test-time augmentation (TTA) on input images and average predictions.\n",
        "\n",
        "        Args:\n",
        "            images (Tensor): Batch of input images.\n",
        "            n (int, optional): Number of augmentation passes. Defaults to 5.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Averaged predictions after TTA.\n",
        "        \"\"\"\n",
        "        aug = tf.keras.Sequential([\n",
        "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "            layers.RandomRotation(0.2),\n",
        "            layers.RandomZoom(0.2)\n",
        "        ])\n",
        "        predictions = [self.model.predict(aug(images), verbose=0) for _ in range(n)]\n",
        "        return np.mean(predictions, axis=0)\n",
        "\n",
        "    def evaluate(self, use_tta: bool = True, show_plots: bool = True):\n",
        "        \"\"\"\n",
        "        Evaluate the model on the test dataset, generate classification report, and optionally plot results.\n",
        "\n",
        "        Args:\n",
        "            use_tta (bool, optional): Whether to use test-time augmentation. Defaults to True.\n",
        "            show_plots (bool, optional): Whether to display classification report and confusion matrix plots. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            dict: Classification report dictionary.\n",
        "        \"\"\"\n",
        "        \"\"\"Evaluate model on test set and generate report.\"\"\"\n",
        "        test_ds = self.create_test_dataset()\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        for images, labels in test_ds:\n",
        "            y_true.extend(labels.numpy())\n",
        "            preds = self.predict_with_tta(images) if use_tta else self.model.predict(images)\n",
        "            y_pred.extend((preds > 0.5).astype(int))\n",
        "\n",
        "        report = classification_report(\n",
        "            y_true, y_pred,\n",
        "            target_names=self.config.CLASS_NAMES,\n",
        "            output_dict=True\n",
        "        )\n",
        "\n",
        "        self.save_results(report, y_true, y_pred)\n",
        "        self.test_results = report\n",
        "\n",
        "        # Display results in notebook\n",
        "        if show_plots:\n",
        "            self.display_results(report, y_true, y_pred)\n",
        "\n",
        "        return report\n",
        "\n",
        "    def save_results(self, report: dict, y_true: list, y_pred: list):\n",
        "        \"\"\"\n",
        "        Save the classification report as JSON and confusion matrix as an image file.\n",
        "\n",
        "        Args:\n",
        "            report (dict): Classification report dictionary.\n",
        "            y_true (list): True labels.\n",
        "            y_pred (list): Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        \"\"\"Save classification report and confusion matrix.\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        results_dir = os.path.join(self.config.MODEL_DIR, 'evaluations')\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "        with open(os.path.join(results_dir, f'report_{timestamp}.json'), 'w') as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=self.config.CLASS_NAMES,\n",
        "                    yticklabels=self.config.CLASS_NAMES)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.savefig(os.path.join(results_dir, f'confusion_matrix_{timestamp}.png'))\n",
        "        plt.close()\n",
        "\n",
        "    def display_results(self, report: dict, y_true: list, y_pred: list):\n",
        "        \"\"\"\n",
        "        Display the classification report, confusion matrix, and key metrics visually.\n",
        "\n",
        "        Args:\n",
        "            report (dict): Classification report dictionary.\n",
        "            y_true (list): True labels.\n",
        "            y_pred (list): Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # Print classification report\n",
        "        print(\"\\n📊 Classification Report:\")\n",
        "        print(classification_report(y_true, y_pred, target_names=self.config.CLASS_NAMES))\n",
        "\n",
        "        # Show confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=self.config.CLASS_NAMES,\n",
        "                    yticklabels=self.config.CLASS_NAMES)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "        # Print key metrics\n",
        "        print(\"\\n🔑 Key Metrics:\")\n",
        "        print(f\"Accuracy: {report['accuracy']:.2%}\")\n",
        "        print(f\"Precision: {report['weighted avg']['precision']:.2%}\")\n",
        "        print(f\"Recall: {report['weighted avg']['recall']:.2%}\")\n",
        "        print(f\"F1-Score: {report['weighted avg']['f1-score']:.2%}\")\n",
        "\n",
        "        # Print per-class metrics\n",
        "        print(\"\\n🎯 Per-Class Performance:\")\n",
        "        for class_name in self.config.CLASS_NAMES:\n",
        "            print(f\"{class_name}:\")\n",
        "            print(f\"  Precision: {report[class_name]['precision']:.2%}\")\n",
        "            print(f\"  Recall: {report[class_name]['recall']:.2%}\")\n",
        "            print(f\"  F1-Score: {report[class_name]['f1-score']:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***🧪 Plant Disease Tester: Model Evaluation & Reporting***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQMPv27cCeru"
      },
      "outputs": [],
      "source": [
        "def main_2(model_path):\n",
        "    \"\"\"\n",
        "    Run evaluation pipeline using PlantDiseaseTester on a saved model.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): File path to the trained model to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        dict: Classification report dictionary containing evaluation metrics.\n",
        "\n",
        "    Raises:\n",
        "        Exception: Propagates any exceptions encountered during evaluation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        config = Config()\n",
        "        tester = PlantDiseaseTester(config, model_path)\n",
        "        report = tester.evaluate(show_plots=True)  \n",
        "\n",
        "        if report['accuracy'] >= 0.95:\n",
        "            print(\"\\n✅ Model achieved ≥ 95% accuracy\")\n",
        "        else:\n",
        "            print(\"\\n⚠️ Model did not reach 95% accuracy\")\n",
        "\n",
        "        return report\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Evaluation failed: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1YoX2jxBCgaX",
        "outputId": "eaccb619-7d10-4e95-f968-2d21b672ca3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25039 files belonging to 2 classes.\n",
            "Using 2503 files for validation.\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     healthy       1.00      1.00      1.00      1247\n",
            "    infected       1.00      1.00      1.00      1256\n",
            "\n",
            "    accuracy                           1.00      2503\n",
            "   macro avg       1.00      1.00      1.00      2503\n",
            "weighted avg       1.00      1.00      1.00      2503\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔑 Key Metrics:\n",
            "Accuracy: 99.72%\n",
            "Precision: 99.72%\n",
            "Recall: 99.72%\n",
            "F1-Score: 99.72%\n",
            "\n",
            "🎯 Per-Class Performance:\n",
            "healthy:\n",
            "  Precision: 99.52%\n",
            "  Recall: 99.92%\n",
            "  F1-Score: 99.72%\n",
            "infected:\n",
            "  Precision: 99.92%\n",
            "  Recall: 99.52%\n",
            "  F1-Score: 99.72%\n",
            "\n",
            "✅ Model achieved ≥ 95% accuracy\n"
          ]
        }
      ],
      "source": [
        "# Then test the model\n",
        "report = main_2(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸🌸 ✿ ✿ ✿ ✿ ✿ 🌸\n",
        "\n",
        "🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿🌿 ───────────────────────────── 🌿\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "  <h1><b>✅🎉 Model 2 Finished Successfully!</b></h1>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
